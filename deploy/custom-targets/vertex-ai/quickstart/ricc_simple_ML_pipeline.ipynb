{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"id":"ur8xi4C7S06n"},"outputs":[],"source":["# Copyright 2023 Google LLC\n","\n","###################################\n","# Created by Ivan on 11mar24\n","# Changed by Riccardo\n","# v1.1 Importing gauic.py and streamlining all the ENV vars there..\n","###################################"]},{"cell_type":"markdown","metadata":{"id":"JAPoU8Sm5E6e"},"source":["# Next24: ML pipelines\n","\n","{TODO: Update the links below.}\n","\n","<table align=\"left\">\n","\n","  <td>\n","    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/notebook_template.ipynb\">\n","      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n","    </a>\n","  </td>\n","  <td>\n","    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/notebook_template.ipynb\">\n","      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n","      View on GitHub\n","    </a>\n","  </td>\n","  <td>\n","    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/notebook_template.ipynb\">\n","      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n","      Open in Vertex AI Workbench\n","    </a>\n","  </td>                                                                                               \n","</table>"]},{"cell_type":"markdown","metadata":{"id":"24743cf4a1e1"},"source":["**_NOTE_**: This notebook has been tested in the following environment:\n","\n","* Python version = 3.9"]},{"cell_type":"markdown","metadata":{"id":"tvgnzT1CKxrO"},"source":["## Overview\n","\n","This notebook shows how to run simple Sklearn-based ML pipelines on Vertex AI Pipelines."]},{"cell_type":"markdown","metadata":{"id":"d975e698c9a4"},"source":["### Objective\n","\n","In this tutorial, you learn how to build ML pipelines interactivly.\n","\n","This tutorial uses the following Google Cloud ML services and resources:\n","\n","- Vertex AI Pipelines\n","- Cloud storage\n","\n","The steps performed include:\n","\n","- Build a data processing component\n","- Build a training component\n","- Build a model eval component\n","- Build a KFP ML pipeline"]},{"cell_type":"markdown","metadata":{"id":"08d289fa873f"},"source":["### Dataset\n","\n","The California housing dataset contains census data of houses found in a given California district in 1990.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"aed92deeb4a0"},"source":["### Costs\n","\n","This tutorial uses billable components of Google Cloud:\n","\n","* Vertex AI\n","* Cloud Storage\n","\n","Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing),\n","and [Cloud Storage pricing](https://cloud.google.com/storage/pricing),\n","and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."]},{"cell_type":"markdown","metadata":{"id":"i7EUnXsZhAGF"},"source":["## Pre Installation (Riccardo)\n","\n","Before doing Ivan stufff, take ENV from... well,  env."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["From GAIC module:\n","游리 PROJECT_ID: rick-and-nardy-demo\n","游리 REGION: us-central1\n","游리 VAI_PIPELINE: vertex-ai-cloud-deploy-pipeline\n","游리 PIPELINE_NAME: ricc-cal-demo-vpipeline\n","游리 BUCKET_URI: gs://rick-and-nardy-demo-rnn-demo24\n","游리 MODEL_NAME: california_reg_model_ricc\n"]}],"source":["import _env_gaic as gaic  # Import the gaic module\n","from _env_gaic import *  # Import the gaic module\n","\n","# Access the variables directly\n","print(\"From GAIC module:\")\n","print(f\"游리 PROJECT_ID: {PROJECT_ID}\")\n","print(f\"游리 REGION: {REGION}\")\n","print(f\"游리 VAI_PIPELINE: {VAI_PIPELINE}\")\n","#print(f\"游리 MODEL_PATH: {MODEL_PATH}\")\n","print(f\"游리 PIPELINE_NAME: {PIPELINE_NAME}\")\n","print(f\"游리 BUCKET_URI: {gaic.BUCKET_URI}\")\n","# Ivan stuff\n","print(f\"游리 MODEL_NAME: {MODEL_NAME}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## Installation\n","\n","Install the following packages required to execute this notebook.\n","\n","{TODO: Suggest using the latest major GA version of each package; i.e., --upgrade}"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10793,"status":"ok","timestamp":1710149544650,"user":{"displayName":"Ivan Nardini","userId":"04192340647469915671"},"user_tz":-60},"id":"2b4ef9b72d43","outputId":"8b7b34ae-387a-44dd-a617-a8e7c7b5731b"},"outputs":[],"source":["! pip3 install --upgrade --quiet numpy pandas scikit-learn xgboost kfp google-cloud-aiplatform google-cloud-pipeline-components"]},{"cell_type":"markdown","metadata":{"id":"58707a750154"},"source":["### Colab only: Uncomment the following cell to restart the kernel."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"f200f10a1da3"},"outputs":[],"source":["# import IPython\n","\n","# app = IPython.Application.instance()\n","# app.kernel.do_shutdown(True)"]},{"cell_type":"markdown","metadata":{"id":"BF1j6f9HApxa"},"source":["## Before you begin\n","\n","### Set up your Google Cloud project\n","\n","**The following steps are required, regardless of your notebook environment.**\n","\n","1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n","\n","2. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n","\n","3. [Enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n","\n","4. If you are running this notebook locally, you need to install the [Cloud SDK](https://cloud.google.com/sdk)."]},{"cell_type":"markdown","metadata":{"id":"WReHDGG5g0XY"},"source":["#### Set your project ID\n","\n","**If you don't know your project ID**, try the following:\n","* Run `gcloud config list`.\n","* Run `gcloud projects list`.\n","* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2074,"status":"ok","timestamp":1710160792801,"user":{"displayName":"Ivan Nardini","userId":"04192340647469915671"},"user_tz":-60},"id":"oM1iC_MfAts1","outputId":"613ceac8-e541-4db9-bec3-1c6579fe537b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Updated property [core/project].\n","Set up project as rick-and-nardy-demo dear Riccardo\n"]}],"source":["#PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n","#PROJECT_ID = \"rick-and-nardy-demo\"\n","\n","# Set the project id\n","! gcloud config set project {PROJECT_ID}\n","! echo Set up project as {PROJECT_ID} dear Riccardo\n"]},{"cell_type":"markdown","metadata":{"id":"region"},"source":["#### Region\n","\n","You can also change the `REGION` variable used by Vertex AI. Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1710160792801,"user":{"displayName":"Ivan Nardini","userId":"04192340647469915671"},"user_tz":-60},"id":"AsE4Jy5aa99c"},"outputs":[],"source":["#REGION = \"us-central1\"  # @param {type: \"string\"}"]},{"cell_type":"markdown","metadata":{"id":"sBCra4QMA2wR"},"source":["### Authenticate your Google Cloud account\n","\n","Depending on your Jupyter environment, you may have to manually authenticate. Follow the relevant instructions below."]},{"cell_type":"markdown","metadata":{"id":"74ccc9e52986"},"source":["**1. Vertex AI Workbench**\n","* Do nothing as you are already authenticated."]},{"cell_type":"markdown","metadata":{"id":"de775a3773ba"},"source":["**2. Local JupyterLab instance, uncomment and run:**"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":234,"status":"ok","timestamp":1710160797340,"user":{"displayName":"Ivan Nardini","userId":"04192340647469915671"},"user_tz":-60},"id":"254614fa0c46"},"outputs":[],"source":["# ! gcloud auth login"]},{"cell_type":"markdown","metadata":{"id":"ef21552ccea8"},"source":["**3. Colab, uncomment and run:**"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":225,"status":"ok","timestamp":1710160797890,"user":{"displayName":"Ivan Nardini","userId":"04192340647469915671"},"user_tz":-60},"id":"603adbbf0532"},"outputs":[],"source":["# from google.colab import auth\n","# auth.authenticate_user()"]},{"cell_type":"markdown","metadata":{"id":"f6b2ccc891ed"},"source":["**4. Service account or other**\n","* See how to grant Cloud Storage permissions to your service account at https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples."]},{"cell_type":"markdown","metadata":{"id":"zgPO1eR3CYjk"},"source":["### Create a Cloud Storage bucket\n","\n","Create a storage bucket to store intermediate artifacts such as datasets.\n","\n","- *{Note to notebook author: For any user-provided strings that need to be unique (like bucket names or model ID's), append \"-unique\" to the end so proper testing can occur}*"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":216,"status":"ok","timestamp":1710160799843,"user":{"displayName":"Ivan Nardini","userId":"04192340647469915671"},"user_tz":-60},"id":"MzGDU7TWdts_"},"outputs":[],"source":["#BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}\n","#BUCKET_URI = f\"gs://{PROJECT_ID}\"\n"]},{"cell_type":"markdown","metadata":{"id":"-EcIXiGsCePi"},"source":["**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3264,"status":"ok","timestamp":1710160803930,"user":{"displayName":"Ivan Nardini","userId":"04192340647469915671"},"user_tz":-60},"id":"NIq7R4HZCfIc","outputId":"702f0e05-9707-4528-ca08-956294ab16e6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Creating gs://rick-and-nardy-demo-rnn-demo24/...\n","ServiceException: 409 A Cloud Storage bucket named 'rick-and-nardy-demo-rnn-demo24' already exists. Try another name. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization.\n"]}],"source":["# This code snippet is authenticating the user in a Google Colab notebook. It allows the user to access Google services and APIs that require authentication, such as Google Drive or Google Cloud services.\n","! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"]},{"cell_type":"markdown","metadata":{"id":"960505627ddf"},"source":["### Import libraries"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":313,"status":"ok","timestamp":1710181313351,"user":{"displayName":"Ivan Nardini","userId":"04192340647469915671"},"user_tz":-60},"id":"PyQmSRbKA8r-"},"outputs":[],"source":["import kfp\n","from kfp import dsl, compiler\n","from google.cloud import aiplatform\n","from kfp.dsl import importer_node\n","from google_cloud_pipeline_components.v1.model import ModelUploadOp, ModelGetOp\n","from google_cloud_pipeline_components.types import artifact_types"]},{"cell_type":"markdown","metadata":{"id":"Pt0FnW-b14Iv"},"source":["### Set variables"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1710181313677,"user":{"displayName":"Ivan Nardini","userId":"04192340647469915671"},"user_tz":-60},"id":"eAOcaAfI16SQ"},"outputs":[],"source":["PIPELINE_ROOT = f\"{BUCKET_URI}/ricc_california_pipeline\"\n","MODEL_PATH = f\"{PIPELINE_ROOT}/model\"\n","#MODEL_NAME = \"california_reg_model\""]},{"cell_type":"markdown","metadata":{"id":"init_aip:mbsdk,all"},"source":["### Initialize Vertex AI SDK for Python\n","\n","Initialize the Vertex AI SDK for Python for your project."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1710181313917,"user":{"displayName":"Ivan Nardini","userId":"04192340647469915671"},"user_tz":-60},"id":"i0LQAYTia99d"},"outputs":[],"source":["aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)"]},{"cell_type":"markdown","metadata":{"id":"gXawVScmgIZx"},"source":["### Create pipeline components"]},{"cell_type":"markdown","metadata":{"id":"CqCHg01xgL43"},"source":["#### Data processing component"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":223,"status":"ok","timestamp":1710181315114,"user":{"displayName":"Ivan Nardini","userId":"04192340647469915671"},"user_tz":-60},"id":"ksm8JP9MgRYt"},"outputs":[],"source":["@dsl.component(base_image='python:3.10', packages_to_install=[\"numpy\", \"pandas\", \"scikit-learn\"])\n","def data_preprocessing_op(processed_dataset: dsl.Output[dsl.Dataset]):\n","\n","  from pathlib import Path as p\n","  from sklearn.datasets import fetch_california_housing\n","  from sklearn.impute import SimpleImputer\n","  from sklearn.preprocessing import StandardScaler\n","  import pandas as pd\n","\n","  housing = fetch_california_housing(as_frame=True)\n","  housing_df = housing['frame']\n","  x_df = housing_df.drop('MedHouseVal', axis=1)\n","  y_df = housing_df[['MedHouseVal']]\n","  processed_x = SimpleImputer().fit_transform(x_df)\n","  processed_x = StandardScaler().fit_transform(processed_x)\n","\n","  processed_x_df = pd.DataFrame(processed_x, columns=x_df.columns)\n","  housing_df = pd.merge(processed_x_df, y_df, left_index=True, right_index=True)\n","\n","  p(processed_dataset.path).mkdir(exist_ok=True)\n","  processed_dataset_path = str(p(processed_dataset.path, \"processed_dataset.csv\"))\n","  housing_df.to_csv(processed_dataset_path, index=False)\n","  processed_dataset.path = processed_dataset_path"]},{"cell_type":"markdown","metadata":{"id":"lkim8CvR7m6G"},"source":["#### Training component"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1710181315919,"user":{"displayName":"Ivan Nardini","userId":"04192340647469915671"},"user_tz":-60},"id":"8U04t84v7m6G"},"outputs":[],"source":["@dsl.component(base_image='python:3.10', packages_to_install=[\"numpy\", \"pandas\", \"scikit-learn\", \"xgboost\"])\n","def training_op(params: dict , model_path: str, processed_dataset: dsl.Input[dsl.Dataset],\n","                trained_model: dsl.Output[dsl.Model], metrics: dsl.Output[dsl.Metrics]):\n","\n","  from pathlib import Path as p\n","  import numpy as np\n","  import pandas as pd\n","  from sklearn.model_selection import train_test_split\n","  from xgboost import XGBRegressor\n","  from sklearn.metrics import mean_squared_error\n","  import joblib\n","\n","  with open(processed_dataset.path, \"r\") as preprocessed_data:\n","      processed_df = pd.read_csv(preprocessed_data)\n","\n","  x = processed_df.drop('MedHouseVal', axis=1)\n","  y = processed_df['MedHouseVal']\n","  X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)\n","  model = XGBRegressor()\n","  if params:\n","    model = XGBRegressor(**params)\n","  model = model.fit(X_train, y_train)\n","  y_pred = model.predict(X_test)\n","  rmse = round(np.sqrt(mean_squared_error(y_test, y_pred)), 3)\n","\n","  metrics.log_metric(\"rmse\", rmse)\n","  model_path = model_path.replace('gs://', '/gcs/')\n","  p(model_path).mkdir(exist_ok=True)\n","  model_filepath = str(p(model_path, \"model.joblib\"))\n","  joblib.dump(model, model_filepath)\n","  trained_model.path = model_filepath"]},{"cell_type":"markdown","metadata":{"id":"EvFIROzNgL1G"},"source":["### Build the pipeline"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":219,"status":"ok","timestamp":1710181347348,"user":{"displayName":"Ivan Nardini","userId":"04192340647469915671"},"user_tz":-60},"id":"PlX3TM7T1SJF"},"outputs":[],"source":["@dsl.pipeline(\n","    name=PIPELINE_NAME,\n",")\n","def pipeline(params: dict = None, model_path:str = None, model_name: str = \"None\"):\n","\n","    \"\"\"A demo pipeline.\"\"\"\n","\n","    preprocessing_data_task = data_preprocessing_op()\n","\n","    training_task = training_op(params=params, model_path=model_path,\n","                                processed_dataset=preprocessing_data_task.outputs['processed_dataset']).after(preprocessing_data_task)\n","\n","    with dsl.If(model_name == \"None\"):\n","\n","      model_importer_task = importer_node.importer(\n","        artifact_uri=model_path,\n","        artifact_class=artifact_types.UnmanagedContainerModel,\n","        metadata={\n","            \"containerSpec\": {\n","                \"imageUri\": \"us-docker.pkg.dev/vertex-ai/prediction/xgboost-cpu.1-7:latest\"\n","            }\n","        },\n","      ).after(training_task)\n","\n","      model_upload_op = ModelUploadOp(\n","          display_name=MODEL_NAME,\n","          unmanaged_container_model=model_importer_task.outputs[\"artifact\"],\n","          version_aliases=['v1']\n","      ).after(model_importer_task)\n","\n","    with dsl.Else():\n","\n","      model_importer_task = importer_node.importer(\n","        artifact_uri=model_path,\n","        artifact_class=artifact_types.UnmanagedContainerModel,\n","        metadata={\n","            \"containerSpec\": {\n","                \"imageUri\": \"us-docker.pkg.dev/vertex-ai/prediction/xgboost-cpu.1-7:latest\"\n","            }\n","        },\n","      ).after(training_task)\n","\n","      get_model_task = ModelGetOp(model_name=model_name).after(model_importer_task)\n","\n","      model_upload_op = ModelUploadOp(\n","          display_name=MODEL_NAME,\n","          unmanaged_container_model=model_importer_task.outputs[\"artifact\"],\n","          parent_model=get_model_task.outputs[\"model\"],\n","          version_aliases=['v2']\n","      ).after(get_model_task)"]},{"cell_type":"markdown","metadata":{"id":"ZBgJq3VbxKmJ"},"source":["### Compile the pipeline"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":221,"status":"ok","timestamp":1710181349453,"user":{"displayName":"Ivan Nardini","userId":"04192340647469915671"},"user_tz":-60},"id":"UZsCqLLG1hED"},"outputs":[],"source":["compiler.Compiler().compile(pipeline_func=pipeline, package_path=\"pipeline.yaml\")"]},{"cell_type":"markdown","metadata":{"id":"aSeGCoAtgLvg"},"source":["### Run the pipeline for training the v1 of the model"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Your browser has been opened to visit:\n","\n","    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8085%2F&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login&state=tD5nuWPhYKzxyFyBOsw5JQHLWNbR3R&access_type=offline&code_challenge=-LEcOPzFKkfk4rIizYufr1j9CHCyuQ6o15xtBUxga1A&code_challenge_method=S256\n","\n","\n","Credentials saved to file: [/usr/local/google/home/ricc/.config/gcloud/application_default_credentials.json]\n","\n","These credentials will be used by any library that requests Application Default Credentials (ADC).\n","\n","Quota project \"rick-and-nardy-demo\" was added to ADC which can be used by Google client libraries for billing and quota. Note that some services may still bill the project owning the resource.\n","Your browser has been opened to visit:\n","\n","    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=32555940559.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8085%2F&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=gfjve9VaeHtlboOi5qc81hcEGdb7Qx&access_type=offline&code_challenge=MQSlwvnxdnC57BAUg-BYnqwWCe_XNEJvi8o-N9GRPmo&code_challenge_method=S256\n","\n","\n","You are now logged in as [ricc@google.com].\n","Your current project is [rick-and-nardy-demo].  You can change this setting by running:\n","  $ gcloud config set project PROJECT_ID\n"]}],"source":["! gcloud auth application-default login\n","! gcloud auth login\n"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":706},"executionInfo":{"elapsed":345659,"status":"error","timestamp":1710181704116,"user":{"displayName":"Ivan Nardini","userId":"04192340647469915671"},"user_tz":-60},"id":"fjEiNUK71x9M","outputId":"5674fd9c-5903-4576-8c5e-3ceddf43644a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Creating PipelineJob\n","PipelineJob created. Resource name: projects/849075740253/locations/us-central1/pipelineJobs/ricc-cal-demo-vpipeline-20240312123521\n","To use this PipelineJob in another session:\n","pipeline_job = aiplatform.PipelineJob.get('projects/849075740253/locations/us-central1/pipelineJobs/ricc-cal-demo-vpipeline-20240312123521')\n","View Pipeline Job:\n","https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/ricc-cal-demo-vpipeline-20240312123521?project=849075740253\n","PipelineJob projects/849075740253/locations/us-central1/pipelineJobs/ricc-cal-demo-vpipeline-20240312123521 current state:\n","3\n","PipelineJob projects/849075740253/locations/us-central1/pipelineJobs/ricc-cal-demo-vpipeline-20240312123521 current state:\n","3\n","PipelineJob projects/849075740253/locations/us-central1/pipelineJobs/ricc-cal-demo-vpipeline-20240312123521 current state:\n","3\n","PipelineJob projects/849075740253/locations/us-central1/pipelineJobs/ricc-cal-demo-vpipeline-20240312123521 current state:\n","3\n"]},{"ename":"RuntimeError","evalue":"Job failed with:\ncode: 9\nmessage: \"The DAG failed because some tasks failed. The failed tasks are: [training-op].; Job (project_id = rick-and-nardy-demo, job_id = 7249623595549196288) is failed due to the above error.; Failed to handle the job: {project_number = 849075740253, job_id = 7249623595549196288}\"\n","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 18\u001b[0m\n\u001b[1;32m      8\u001b[0m job \u001b[38;5;241m=\u001b[39m aiplatform\u001b[38;5;241m.\u001b[39mPipelineJob(\n\u001b[1;32m      9\u001b[0m     display_name\u001b[38;5;241m=\u001b[39mPIPELINE_NAME, \u001b[38;5;66;03m#\"california-demo-pipeline\",\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     template_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipeline.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     enable_caching\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# takes 2-3minutes.\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/google/cloud/aiplatform/pipeline_jobs.py:323\u001b[0m, in \u001b[0;36mPipelineJob.run\u001b[0;34m(self, service_account, network, reserved_ip_ranges, sync, create_request_timeout)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run this configured PipelineJob and monitor the job until completion.\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \n\u001b[1;32m    303\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;124;03m        Optional. The timeout for the create request in seconds.\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    321\u001b[0m network \u001b[38;5;241m=\u001b[39m network \u001b[38;5;129;01mor\u001b[39;00m initializer\u001b[38;5;241m.\u001b[39mglobal_config\u001b[38;5;241m.\u001b[39mnetwork\n\u001b[0;32m--> 323\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice_account\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice_account\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreserved_ip_ranges\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreserved_ip_ranges\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[43msync\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msync\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/google/cloud/aiplatform/base.py:850\u001b[0m, in \u001b[0;36moptional_sync.<locals>.optional_run_in_thread.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m    849\u001b[0m         VertexAiResourceNounWithFutureManager\u001b[38;5;241m.\u001b[39mwait(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 850\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;66;03m# callbacks to call within the Future (in same Thread)\u001b[39;00m\n\u001b[1;32m    853\u001b[0m internal_callbacks \u001b[38;5;241m=\u001b[39m []\n","File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/google/cloud/aiplatform/pipeline_jobs.py:366\u001b[0m, in \u001b[0;36mPipelineJob._run\u001b[0;34m(self, service_account, network, reserved_ip_ranges, sync, create_request_timeout)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Helper method to ensure network synchronization and to run\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;124;03mthe configured PipelineJob and monitor the job until completion.\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;124;03m        Optional. The timeout for the create request in seconds.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[1;32m    360\u001b[0m     service_account\u001b[38;5;241m=\u001b[39mservice_account,\n\u001b[1;32m    361\u001b[0m     network\u001b[38;5;241m=\u001b[39mnetwork,\n\u001b[1;32m    362\u001b[0m     reserved_ip_ranges\u001b[38;5;241m=\u001b[39mreserved_ip_ranges,\n\u001b[1;32m    363\u001b[0m     create_request_timeout\u001b[38;5;241m=\u001b[39mcreate_request_timeout,\n\u001b[1;32m    364\u001b[0m )\n\u001b[0;32m--> 366\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_block_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/google/cloud/aiplatform/pipeline_jobs.py:615\u001b[0m, in \u001b[0;36mPipelineJob._block_until_complete\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;66;03m# Error is only populated when the job state is\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;66;03m# JOB_STATE_FAILED or JOB_STATE_CANCELLED.\u001b[39;00m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gca_resource\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;129;01min\u001b[39;00m _PIPELINE_ERROR_STATES:\n\u001b[0;32m--> 615\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJob failed with:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gca_resource\u001b[38;5;241m.\u001b[39merror)\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    617\u001b[0m     _LOGGER\u001b[38;5;241m.\u001b[39mlog_action_completed_against_resource(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m)\n","\u001b[0;31mRuntimeError\u001b[0m: Job failed with:\ncode: 9\nmessage: \"The DAG failed because some tasks failed. The failed tasks are: [training-op].; Job (project_id = rick-and-nardy-demo, job_id = 7249623595549196288) is failed due to the above error.; Failed to handle the job: {project_number = 849075740253, job_id = 7249623595549196288}\"\n"]}],"source":["# [ricc] Note this requires a further `gcloud auth application-default login`\n","\n","my_labels = {\n","    \"env\": \"ricc-testing\",\n","    \"type\": \"training\"\n","}\n","\n","job = aiplatform.PipelineJob(\n","    display_name=PIPELINE_NAME, #\"california-demo-pipeline\",\n","    template_path=\"pipeline.yaml\",\n","    pipeline_root=PIPELINE_ROOT,\n","    parameter_values={'model_path': MODEL_PATH},\n","    labels=my_labels,\n","    enable_caching=True\n",")\n","\n","# takes 2-3minutes.\n","job.run()"]},{"cell_type":"markdown","metadata":{"id":"ZJVYBK6OE-CR"},"source":["### Run the pipeline for training the v2 of the model"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"aborted","timestamp":1710181704117,"user":{"displayName":"Ivan Nardini","userId":"04192340647469915671"},"user_tz":-60},"id":"MZznChZdyiE8"},"outputs":[],"source":["model_list = aiplatform.Model.list(filter=f\"display_name={MODEL_NAME}\", order_by=\"create_time\")\n","model_name = model_list[0].name"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":247697,"status":"ok","timestamp":1710180915143,"user":{"displayName":"Ivan Nardini","userId":"04192340647469915671"},"user_tz":-60},"id":"GB01p4cWEGN-","outputId":"79555af3-a904-42c7-a0d0-ed3983c5a0fc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Creating PipelineJob\n","PipelineJob created. Resource name: projects/849075740253/locations/us-central1/pipelineJobs/california-demo-pipeline-20240312113125\n","To use this PipelineJob in another session:\n","pipeline_job = aiplatform.PipelineJob.get('projects/849075740253/locations/us-central1/pipelineJobs/california-demo-pipeline-20240312113125')\n","View Pipeline Job:\n","https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/california-demo-pipeline-20240312113125?project=849075740253\n","PipelineJob projects/849075740253/locations/us-central1/pipelineJobs/california-demo-pipeline-20240312113125 current state:\n","3\n","PipelineJob projects/849075740253/locations/us-central1/pipelineJobs/california-demo-pipeline-20240312113125 current state:\n","3\n","PipelineJob projects/849075740253/locations/us-central1/pipelineJobs/california-demo-pipeline-20240312113125 current state:\n","3\n","PipelineJob projects/849075740253/locations/us-central1/pipelineJobs/california-demo-pipeline-20240312113125 current state:\n","3\n","PipelineJob projects/849075740253/locations/us-central1/pipelineJobs/california-demo-pipeline-20240312113125 current state:\n","3\n","PipelineJob projects/849075740253/locations/us-central1/pipelineJobs/california-demo-pipeline-20240312113125 current state:\n","3\n","PipelineJob run completed. Resource name: projects/849075740253/locations/us-central1/pipelineJobs/california-demo-pipeline-20240312113125\n"]}],"source":["job = aiplatform.PipelineJob(\n","    display_name=PIPELINE_NAME,\n","    template_path=\"pipeline.yaml\",\n","    pipeline_root=PIPELINE_ROOT,\n","    parameter_values={'params': {'learning_rate': 0.0001,\n","                                 'n_estimators': 4000,\n","                                 'max_depth': 20,\n","                                 'random_state': 8},\n","                      'model_path': MODEL_PATH,\n","                      'model_name': model_name\n","                      },\n","    enable_caching=True\n",")\n","\n","job.run()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
